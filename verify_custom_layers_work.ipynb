{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.232288e-16</td>\n",
       "      <td>-1.243450e-17</td>\n",
       "      <td>6.098825e-17</td>\n",
       "      <td>-3.597123e-17</td>\n",
       "      <td>-1.181277e-16</td>\n",
       "      <td>1.894781e-17</td>\n",
       "      <td>-5.921189e-18</td>\n",
       "      <td>-1.551352e-16</td>\n",
       "      <td>3.780679e-16</td>\n",
       "      <td>-2.285579e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.042869e-16</td>\n",
       "      <td>5.234331e-16</td>\n",
       "      <td>2.275217e-16</td>\n",
       "      <td>-8.230453e-16</td>\n",
       "      <td>-3.390621e-16</td>\n",
       "      <td>-1.697901e-16</td>\n",
       "      <td>-1.496581e-16</td>\n",
       "      <td>5.092223e-17</td>\n",
       "      <td>-5.921189e-18</td>\n",
       "      <td>2.593481e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.255751e+00</td>\n",
       "      <td>-1.421168e+00</td>\n",
       "      <td>-2.327800e+00</td>\n",
       "      <td>-1.090848e+00</td>\n",
       "      <td>-6.914318e-01</td>\n",
       "      <td>-1.988075e+00</td>\n",
       "      <td>-2.331623e+00</td>\n",
       "      <td>-1.705412e+00</td>\n",
       "      <td>-1.296348e+00</td>\n",
       "      <td>-1.447498e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.357970e-01</td>\n",
       "      <td>-3.068659e+00</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-4.579055e-01</td>\n",
       "      <td>-1.598281e+00</td>\n",
       "      <td>-1.522904e-01</td>\n",
       "      <td>-4.916522e-01</td>\n",
       "      <td>-1.337200e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.255751e+00</td>\n",
       "      <td>-7.470431e-01</td>\n",
       "      <td>-4.744560e-01</td>\n",
       "      <td>-6.914204e-01</td>\n",
       "      <td>-6.914318e-01</td>\n",
       "      <td>-3.230206e-01</td>\n",
       "      <td>-9.247708e-01</td>\n",
       "      <td>-7.950499e-01</td>\n",
       "      <td>-1.296348e+00</td>\n",
       "      <td>-7.574464e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.357970e-01</td>\n",
       "      <td>3.258753e-01</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-4.579055e-01</td>\n",
       "      <td>-1.598281e+00</td>\n",
       "      <td>-1.522904e-01</td>\n",
       "      <td>-4.916522e-01</td>\n",
       "      <td>-1.337200e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.582802e-01</td>\n",
       "      <td>-2.414492e-01</td>\n",
       "      <td>-4.744560e-01</td>\n",
       "      <td>-3.283049e-01</td>\n",
       "      <td>-6.914318e-01</td>\n",
       "      <td>-3.230206e-01</td>\n",
       "      <td>4.820813e-01</td>\n",
       "      <td>1.153126e-01</td>\n",
       "      <td>-3.440846e-01</td>\n",
       "      <td>-2.399079e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.357970e-01</td>\n",
       "      <td>3.258753e-01</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-4.579055e-01</td>\n",
       "      <td>6.256722e-01</td>\n",
       "      <td>-1.522904e-01</td>\n",
       "      <td>-4.916522e-01</td>\n",
       "      <td>7.478312e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.136662e+00</td>\n",
       "      <td>2.641447e-01</td>\n",
       "      <td>1.378888e+00</td>\n",
       "      <td>2.526800e-01</td>\n",
       "      <td>5.858437e-01</td>\n",
       "      <td>1.342034e+00</td>\n",
       "      <td>4.820813e-01</td>\n",
       "      <td>1.025675e+00</td>\n",
       "      <td>6.081791e-01</td>\n",
       "      <td>5.363999e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.357970e-01</td>\n",
       "      <td>3.258753e-01</td>\n",
       "      <td>-2.111119e-01</td>\n",
       "      <td>-4.579055e-01</td>\n",
       "      <td>6.256722e-01</td>\n",
       "      <td>-1.522904e-01</td>\n",
       "      <td>-4.916522e-01</td>\n",
       "      <td>7.478312e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.136662e+00</td>\n",
       "      <td>3.297708e+00</td>\n",
       "      <td>1.378888e+00</td>\n",
       "      <td>5.517855e+00</td>\n",
       "      <td>1.863119e+00</td>\n",
       "      <td>1.342034e+00</td>\n",
       "      <td>1.888934e+00</td>\n",
       "      <td>1.025675e+00</td>\n",
       "      <td>1.560443e+00</td>\n",
       "      <td>3.382862e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.736824e+00</td>\n",
       "      <td>1.786041e+00</td>\n",
       "      <td>2.977989e+00</td>\n",
       "      <td>3.258753e-01</td>\n",
       "      <td>4.736824e+00</td>\n",
       "      <td>2.183857e+00</td>\n",
       "      <td>6.256722e-01</td>\n",
       "      <td>6.566403e+00</td>\n",
       "      <td>2.033958e+00</td>\n",
       "      <td>7.478312e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean  -2.232288e-16 -1.243450e-17  6.098825e-17 -3.597123e-17 -1.181277e-16   \n",
       "std    1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min   -1.255751e+00 -1.421168e+00 -2.327800e+00 -1.090848e+00 -6.914318e-01   \n",
       "25%   -1.255751e+00 -7.470431e-01 -4.744560e-01 -6.914204e-01 -6.914318e-01   \n",
       "50%   -4.582802e-01 -2.414492e-01 -4.744560e-01 -3.283049e-01 -6.914318e-01   \n",
       "75%    1.136662e+00  2.641447e-01  1.378888e+00  2.526800e-01  5.858437e-01   \n",
       "max    1.136662e+00  3.297708e+00  1.378888e+00  5.517855e+00  1.863119e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean   1.894781e-17 -5.921189e-18 -1.551352e-16  3.780679e-16 -2.285579e-16   \n",
       "std    1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min   -1.988075e+00 -2.331623e+00 -1.705412e+00 -1.296348e+00 -1.447498e+00   \n",
       "25%   -3.230206e-01 -9.247708e-01 -7.950499e-01 -1.296348e+00 -7.574464e-01   \n",
       "50%   -3.230206e-01  4.820813e-01  1.153126e-01 -3.440846e-01 -2.399079e-01   \n",
       "75%    1.342034e+00  4.820813e-01  1.025675e+00  6.081791e-01  5.363999e-01   \n",
       "max    1.342034e+00  1.888934e+00  1.025675e+00  1.560443e+00  3.382862e+00   \n",
       "\n",
       "       ...            14            15            16            17  \\\n",
       "count  ...  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean   ...  1.042869e-16  5.234331e-16  2.275217e-16 -8.230453e-16   \n",
       "std    ...  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min    ... -2.111119e-01 -5.598974e-01 -3.357970e-01 -3.068659e+00   \n",
       "25%    ... -2.111119e-01 -5.598974e-01 -3.357970e-01  3.258753e-01   \n",
       "50%    ... -2.111119e-01 -5.598974e-01 -3.357970e-01  3.258753e-01   \n",
       "75%    ... -2.111119e-01 -5.598974e-01 -3.357970e-01  3.258753e-01   \n",
       "max    ...  4.736824e+00  1.786041e+00  2.977989e+00  3.258753e-01   \n",
       "\n",
       "                 18            19            20            21            22  \\\n",
       "count  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean  -3.390621e-16 -1.697901e-16 -1.496581e-16  5.092223e-17 -5.921189e-18   \n",
       "std    1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min   -2.111119e-01 -4.579055e-01 -1.598281e+00 -1.522904e-01 -4.916522e-01   \n",
       "25%   -2.111119e-01 -4.579055e-01 -1.598281e+00 -1.522904e-01 -4.916522e-01   \n",
       "50%   -2.111119e-01 -4.579055e-01  6.256722e-01 -1.522904e-01 -4.916522e-01   \n",
       "75%   -2.111119e-01 -4.579055e-01  6.256722e-01 -1.522904e-01 -4.916522e-01   \n",
       "max    4.736824e+00  2.183857e+00  6.256722e-01  6.566403e+00  2.033958e+00   \n",
       "\n",
       "                 23  \n",
       "count  7.500000e+02  \n",
       "mean   2.593481e-16  \n",
       "std    1.000667e+00  \n",
       "min   -1.337200e+00  \n",
       "25%   -1.337200e+00  \n",
       "50%    7.478312e-01  \n",
       "75%    7.478312e-01  \n",
       "max    7.478312e-01  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "a = tfds.load('german_credit_numeric')\n",
    "df = tfds.as_dataframe(a['train'])\n",
    "features = pd.DataFrame(df['features'].tolist()).values\n",
    "targets = df['label'].values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(features, targets)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1644783814502942"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CustomLayers import FeatureReversalNoise\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(24)))\n",
    "model.add(FeatureReversalNoise(input_vector_length=24, prob=.2))\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Dense(1, activation='tanh'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.01), loss='mse')\n",
    "model.fit(x=X_train,y=y_train, verbose=0, epochs=10, validation_split=.2)\n",
    "y_preds = model.predict(X_test)\n",
    "mean_squared_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "def model_builder_factory(n_features,\n",
    "                          prob,\n",
    "                          min_layers,\n",
    "                          max_layers,\n",
    "                          min_hidden_nodes,\n",
    "                          max_hidden_nodes,\n",
    "                          include_prob):\n",
    "  \"\"\"\n",
    "  returns the model_builder function based on the hyper parameters passed \n",
    "  \"\"\"\n",
    "  def hypermodel(hp):\n",
    "    glorrot_init = tf.keras.initializers.GlorotUniform() # A smarter way to set inital weights\n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(n_features)))\n",
    "    if include_prob:\n",
    "      model.add(FeatureReversalNoise(input_vector_length=n_features,prob=prob))\n",
    "    \n",
    "    nodes_per_layer = []\n",
    "    for i in range(max_layers):\n",
    "      hp_units = hp.Int(f'Dense_layer{i}',\n",
    "                      min_value=min_hidden_nodes,\n",
    "                      max_value=max_hidden_nodes,\n",
    "                      step=1)\n",
    "      nodes_per_layer.append(hp_units)\n",
    "\n",
    "    for i in range(hp.Int('n_layers', min_value=min_layers, max_value=max_layers, step=1)):\n",
    "      model.add(keras.layers.Dense(units=nodes_per_layer[i],\n",
    "                                   activation='relu',\n",
    "                                   kernel_initializer=glorrot_init))\n",
    "      \n",
    "    model.add(keras.layers.Dense(1,activation='tanh'))\n",
    "    # hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3,])\n",
    "    hp_beta_1 = hp.Choice('beta_1', values=[.8,.9,.92,.94,.95])\n",
    "    hp_beta_2 = hp.Choice('beta_2', values=[.98,.99,.995,.999])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=.01,\n",
    "                                                  beta_1=hp_beta_1,\n",
    "                                                  beta_2=hp_beta_2),\n",
    "                  loss='mse', metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "  return hypermodel\n",
    "\n",
    "\n",
    "hypermodel = model_builder_factory(24,.1,1,3,2,8,include_prob=True)\n",
    "tuner = kt.RandomSearch(hypermodel=hypermodel,\n",
    "                          objective='mse',\n",
    "                          max_trials=10,\n",
    "                          overwrite=True,\n",
    "                          #directory='/kerasproject',\n",
    "                          project_name='testLayers')\n",
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=3)\n",
    "tuner.search(x=X_train,y=y_train,      \n",
    "            verbose=0,\n",
    "            epochs=10,\n",
    "            batch_size=2**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions of the model in memory are the same as the model loaded from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=5)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train,y_train,epochs=20,batch_size=2**8,verbose=0)\n",
    "y_preds_in_memory = best_model.predict(X_test)\n",
    "\n",
    "best_model.save(f'model.h5',save_format='h5')\n",
    "saved_model = tf.keras.models.load_model(\"model.h5\")\n",
    "y_preds_from_disk = saved_model.predict(X_test)\n",
    "print('Are the predictions of the model in memory are the same as the model loaded from disk?')\n",
    "np.all(y_preds_in_memory == y_preds_from_disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values should be the same. If they are not that means you got an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
