{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 11:55:47.699945: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-05 11:55:47.699961: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-05 11:55:48.940813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-05 11:55:48.940829: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-05 11:55:48.940839: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (parkerburchett-desktop): /proc/driver/nvidia/version does not exist\n",
      "2022-01-05 11:55:48.940986: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-05 11:55:48.970385: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.710751e-17</td>\n",
       "      <td>6.602126e-17</td>\n",
       "      <td>-3.019807e-16</td>\n",
       "      <td>-1.206442e-16</td>\n",
       "      <td>-7.096175e-17</td>\n",
       "      <td>-1.746751e-17</td>\n",
       "      <td>-1.653492e-16</td>\n",
       "      <td>4.221068e-16</td>\n",
       "      <td>-1.684578e-16</td>\n",
       "      <td>2.874367e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.571336e-16</td>\n",
       "      <td>2.353673e-17</td>\n",
       "      <td>9.414691e-17</td>\n",
       "      <td>-3.449093e-17</td>\n",
       "      <td>-4.366877e-18</td>\n",
       "      <td>2.304823e-16</td>\n",
       "      <td>-1.731948e-16</td>\n",
       "      <td>2.617166e-16</td>\n",
       "      <td>9.414691e-17</td>\n",
       "      <td>-5.269859e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "      <td>1.000667e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.255674e+00</td>\n",
       "      <td>-1.389418e+00</td>\n",
       "      <td>-2.367519e+00</td>\n",
       "      <td>-1.083393e+00</td>\n",
       "      <td>-7.175368e-01</td>\n",
       "      <td>-1.948150e+00</td>\n",
       "      <td>-2.402562e+00</td>\n",
       "      <td>-1.656978e+00</td>\n",
       "      <td>-1.314940e+00</td>\n",
       "      <td>-1.453101e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.932470e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.308587e-01</td>\n",
       "      <td>-3.219260e+00</td>\n",
       "      <td>-2.145346e-01</td>\n",
       "      <td>-4.557735e-01</td>\n",
       "      <td>-1.619626e+00</td>\n",
       "      <td>-1.568125e-01</td>\n",
       "      <td>-5.041633e-01</td>\n",
       "      <td>-1.306745e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.255674e+00</td>\n",
       "      <td>-7.182017e-01</td>\n",
       "      <td>-5.140333e-01</td>\n",
       "      <td>-6.903760e-01</td>\n",
       "      <td>-7.175368e-01</td>\n",
       "      <td>-2.934360e-01</td>\n",
       "      <td>-9.892902e-01</td>\n",
       "      <td>-7.551394e-01</td>\n",
       "      <td>-1.314940e+00</td>\n",
       "      <td>-7.580038e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.932470e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.308587e-01</td>\n",
       "      <td>3.106304e-01</td>\n",
       "      <td>-2.145346e-01</td>\n",
       "      <td>-4.557735e-01</td>\n",
       "      <td>-1.619626e+00</td>\n",
       "      <td>-1.568125e-01</td>\n",
       "      <td>-5.041633e-01</td>\n",
       "      <td>-1.306745e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.575763e-01</td>\n",
       "      <td>-2.147893e-01</td>\n",
       "      <td>-5.140333e-01</td>\n",
       "      <td>-3.330878e-01</td>\n",
       "      <td>-7.175368e-01</td>\n",
       "      <td>-2.934360e-01</td>\n",
       "      <td>4.239815e-01</td>\n",
       "      <td>1.466991e-01</td>\n",
       "      <td>-3.527889e-01</td>\n",
       "      <td>-2.366807e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.932470e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.308587e-01</td>\n",
       "      <td>3.106304e-01</td>\n",
       "      <td>-2.145346e-01</td>\n",
       "      <td>-4.557735e-01</td>\n",
       "      <td>6.174265e-01</td>\n",
       "      <td>-1.568125e-01</td>\n",
       "      <td>-5.041633e-01</td>\n",
       "      <td>7.652605e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.138620e+00</td>\n",
       "      <td>2.886231e-01</td>\n",
       "      <td>1.339452e+00</td>\n",
       "      <td>2.743020e-01</td>\n",
       "      <td>5.368982e-01</td>\n",
       "      <td>5.339211e-01</td>\n",
       "      <td>4.239815e-01</td>\n",
       "      <td>1.048538e+00</td>\n",
       "      <td>6.093626e-01</td>\n",
       "      <td>5.453040e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.932470e-01</td>\n",
       "      <td>-5.598974e-01</td>\n",
       "      <td>-3.308587e-01</td>\n",
       "      <td>3.106304e-01</td>\n",
       "      <td>-2.145346e-01</td>\n",
       "      <td>-4.557735e-01</td>\n",
       "      <td>6.174265e-01</td>\n",
       "      <td>-1.568125e-01</td>\n",
       "      <td>-5.041633e-01</td>\n",
       "      <td>7.652605e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.138620e+00</td>\n",
       "      <td>4.315922e+00</td>\n",
       "      <td>1.339452e+00</td>\n",
       "      <td>4.526031e+00</td>\n",
       "      <td>1.791333e+00</td>\n",
       "      <td>1.361278e+00</td>\n",
       "      <td>1.837253e+00</td>\n",
       "      <td>1.048538e+00</td>\n",
       "      <td>1.571514e+00</td>\n",
       "      <td>3.412581e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.174725e+00</td>\n",
       "      <td>1.786041e+00</td>\n",
       "      <td>3.022439e+00</td>\n",
       "      <td>3.106304e-01</td>\n",
       "      <td>4.661252e+00</td>\n",
       "      <td>2.194072e+00</td>\n",
       "      <td>6.174265e-01</td>\n",
       "      <td>6.377042e+00</td>\n",
       "      <td>1.983484e+00</td>\n",
       "      <td>7.652605e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean   9.710751e-17  6.602126e-17 -3.019807e-16 -1.206442e-16 -7.096175e-17   \n",
       "std    1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min   -1.255674e+00 -1.389418e+00 -2.367519e+00 -1.083393e+00 -7.175368e-01   \n",
       "25%   -1.255674e+00 -7.182017e-01 -5.140333e-01 -6.903760e-01 -7.175368e-01   \n",
       "50%   -4.575763e-01 -2.147893e-01 -5.140333e-01 -3.330878e-01 -7.175368e-01   \n",
       "75%    1.138620e+00  2.886231e-01  1.339452e+00  2.743020e-01  5.368982e-01   \n",
       "max    1.138620e+00  4.315922e+00  1.339452e+00  4.526031e+00  1.791333e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean  -1.746751e-17 -1.653492e-16  4.221068e-16 -1.684578e-16  2.874367e-16   \n",
       "std    1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min   -1.948150e+00 -2.402562e+00 -1.656978e+00 -1.314940e+00 -1.453101e+00   \n",
       "25%   -2.934360e-01 -9.892902e-01 -7.551394e-01 -1.314940e+00 -7.580038e-01   \n",
       "50%   -2.934360e-01  4.239815e-01  1.466991e-01 -3.527889e-01 -2.366807e-01   \n",
       "75%    5.339211e-01  4.239815e-01  1.048538e+00  6.093626e-01  5.453040e-01   \n",
       "max    1.361278e+00  1.837253e+00  1.048538e+00  1.571514e+00  3.412581e+00   \n",
       "\n",
       "       ...            14            15            16            17  \\\n",
       "count  ...  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean   ... -1.571336e-16  2.353673e-17  9.414691e-17 -3.449093e-17   \n",
       "std    ...  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min    ... -1.932470e-01 -5.598974e-01 -3.308587e-01 -3.219260e+00   \n",
       "25%    ... -1.932470e-01 -5.598974e-01 -3.308587e-01  3.106304e-01   \n",
       "50%    ... -1.932470e-01 -5.598974e-01 -3.308587e-01  3.106304e-01   \n",
       "75%    ... -1.932470e-01 -5.598974e-01 -3.308587e-01  3.106304e-01   \n",
       "max    ...  5.174725e+00  1.786041e+00  3.022439e+00  3.106304e-01   \n",
       "\n",
       "                 18            19            20            21            22  \\\n",
       "count  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02  7.500000e+02   \n",
       "mean  -4.366877e-18  2.304823e-16 -1.731948e-16  2.617166e-16  9.414691e-17   \n",
       "std    1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00  1.000667e+00   \n",
       "min   -2.145346e-01 -4.557735e-01 -1.619626e+00 -1.568125e-01 -5.041633e-01   \n",
       "25%   -2.145346e-01 -4.557735e-01 -1.619626e+00 -1.568125e-01 -5.041633e-01   \n",
       "50%   -2.145346e-01 -4.557735e-01  6.174265e-01 -1.568125e-01 -5.041633e-01   \n",
       "75%   -2.145346e-01 -4.557735e-01  6.174265e-01 -1.568125e-01 -5.041633e-01   \n",
       "max    4.661252e+00  2.194072e+00  6.174265e-01  6.377042e+00  1.983484e+00   \n",
       "\n",
       "                 23  \n",
       "count  7.500000e+02  \n",
       "mean  -5.269859e-17  \n",
       "std    1.000667e+00  \n",
       "min   -1.306745e+00  \n",
       "25%   -1.306745e+00  \n",
       "50%    7.652605e-01  \n",
       "75%    7.652605e-01  \n",
       "max    7.652605e-01  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "a = tfds.load('german_credit_numeric')\n",
    "df = tfds.as_dataframe(a['train'])\n",
    "features = pd.DataFrame(df['features'].tolist()).values\n",
    "targets = df['label'].values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(features, targets)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1762640134788755"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CustomLayers import FeatureReversalNoise\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(24)))\n",
    "model.add(FeatureReversalNoise(input_vector_length=24, prob=.2))\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Dense(1, activation='tanh'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.01), loss='mse')\n",
    "model.fit(x=X_train,y=y_train, verbose=0, epochs=10, validation_split=.2)\n",
    "y_preds = model.predict(X_test)\n",
    "mean_squared_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "def model_builder_factory(n_features,\n",
    "                          prob,\n",
    "                          min_layers,\n",
    "                          max_layers,\n",
    "                          min_hidden_nodes,\n",
    "                          max_hidden_nodes,\n",
    "                          include_prob):\n",
    "  \"\"\"\n",
    "  returns the model_builder function based on the hyper parameters passed \n",
    "  \"\"\"\n",
    "  def hypermodel(hp):\n",
    "    glorrot_init = tf.keras.initializers.GlorotUniform() # A smarter way to set inital weights\n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(n_features)))\n",
    "    if include_prob:\n",
    "      model.add(FeatureReversalNoise(input_vector_length=n_features,prob=prob))\n",
    "    \n",
    "    nodes_per_layer = []\n",
    "    for i in range(max_layers):\n",
    "      hp_units = hp.Int(f'Dense_layer{i}',\n",
    "                      min_value=min_hidden_nodes,\n",
    "                      max_value=max_hidden_nodes,\n",
    "                      step=1)\n",
    "      nodes_per_layer.append(hp_units)\n",
    "\n",
    "    for i in range(hp.Int('n_layers', min_value=min_layers, max_value=max_layers, step=1)):\n",
    "      model.add(keras.layers.Dense(units=nodes_per_layer[i],\n",
    "                                   activation='relu',\n",
    "                                   kernel_initializer=glorrot_init))\n",
    "      \n",
    "    model.add(keras.layers.Dense(1,activation='tanh'))\n",
    "    # hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3,])\n",
    "    hp_beta_1 = hp.Choice('beta_1', values=[.8,.9,.92,.94,.95])\n",
    "    hp_beta_2 = hp.Choice('beta_2', values=[.98,.99,.995,.999])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=.01,\n",
    "                                                  beta_1=hp_beta_1,\n",
    "                                                  beta_2=hp_beta_2),\n",
    "                  loss='mse', metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "  return hypermodel\n",
    "\n",
    "\n",
    "hypermodel = model_builder_factory(24,.1,1,3,2,8,include_prob=True)\n",
    "tuner = kt.RandomSearch(hypermodel=hypermodel,\n",
    "                          objective='mse',\n",
    "                          max_trials=10,\n",
    "                          overwrite=True,\n",
    "                          #directory='/kerasproject',\n",
    "                          project_name='testLayers')\n",
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=3)\n",
    "tuner.search(x=X_train,y=y_train,      \n",
    "            verbose=0,\n",
    "            epochs=10,\n",
    "            batch_size=2**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the predictions of the model in memory are the same as the model loaded from disk?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=5)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train,y_train,epochs=20,batch_size=2**8,verbose=0)\n",
    "y_preds_in_memory = best_model.predict(X_test)\n",
    "\n",
    "best_model.save(f'model.h5',save_format='h5')\n",
    "saved_model = tf.keras.models.load_model(\"model.h5\")\n",
    "y_preds_from_disk = saved_model.predict(X_test)\n",
    "print('Are the predictions of the model in memory are the same as the model loaded from disk?')\n",
    "np.all(y_preds_in_memory == y_preds_from_disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values should be the same. If they are not that means you got an error"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
